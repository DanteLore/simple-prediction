{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results of NLP training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 100)           539800    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 500)              702000    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5398)              2704398   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,946,198\n",
      "Trainable params: 3,946,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "\n",
    "# Load the tokens\n",
    "with open(\"./data/nlp_models/tokenizer.json\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "# Create the reverse lookup for tokens\n",
    "word_lookup = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('./data/nlp_models/model_2023_1_22_15_53.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 11:57:56.140330: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-23 11:57:56.434067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-23 11:57:56.689866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-23 11:57:56.704353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a data strategy is important because im kind picture frames and working with data platforms or life data in the sql file and column as a very simple before the class. the dataset we just to data in a series of actual cucumber. were time to find the ideal place for testing because so which others you have data quality but each up so platform to probably due to make well\n",
      "-\n",
      "it flies really hard but then, how can they have another scala app and full of use as i it doesnt need to the table semantics are the killer feature here. the single responsibility, immutable datasets can take steps for about the properties address of a python on it to build a chance\n",
      "-\n",
      "the diesel engine pumps out black smoke because, select there were sort of continuous integration. html, if the top as many bugs as world where key, the middle of over the json schema back end code i called mine is two parts of the system. id, do they look too!\n",
      "-\n",
      "this article is about angularjs. there are all sorts of sensible reasons as well as a week.\n",
      "-\n",
      "so we made one out of a chunk of course, i think ive proved that by far the above my best attempt. hit three and why your data is a user stories through code the api and a to join and filter in sql means that defining the long wasnt to they can all honesty, was a new years should like the table, how to select cloudwatch flight hidden pretty system, data is not sure its fixing a simple.\n",
      "-\n",
      "if a train is delayed or cancelled id hand. didnt get the command line options\n",
      "-\n",
      "here we use ksql to create a new table to select your own low, one gave the tool was very little. the code i wrote the motors have lots of the data from the same sort of big data? and finally and the code.\n",
      "-\n",
      "looks like there are four beers but dips top an etl of work is a strength above 10 which is a silly strength for a beer really! as model reviews for larger online businesses analytics data is now, need off and in late nights.\n",
      "-\n",
      "how much you invest in your data engineering capability is dependent on your own ambition and needs and install the year! i could convert for the x axis is that the time and managed out and the code.\n",
      "-\n",
      "data strategy. i believe there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there there you say all four was tried to be made available into i couldnt, while led that i tried to be made available as while i made i made i made i made i made i made i made i made i made i made i made\n",
      "-\n",
      "quadcopters. i believe there are many python libraries i used to involve commenting out why its not find this point need to read that i found writing need to turn crappy them to a particular service are many things on the whole world has more boxes chuffer.\n",
      "-\n",
      "mechanisms for driving and measuring quality in data are very different to those which work for traditional? in our the table\n",
      "-\n",
      "idempotent operations stop architecture about soldering up your own unique map, but doesnt need hinges on the right combination of input variables together you, yet to select, yet made is made up an internet years still simply enough up of scrap and python libraries image the bufferblock stencilled! these days a file is devoted succeed and means more papers, need.\n",
      "-\n",
      "a couple of weeks ago i made a bunkbed, so i have 20 custom queries that all relate to support them there is some people from scrap wood for one, the xml in each file and off and ready to write pretty and column the table and helps the made. note that in a dropzone ml, this\n",
      "-\n",
      "some may be expecting this post to be about technology specific tools like snowflake, bigquery, databricks or some interesting bit in about the development and quick and more data too when the minute elapses, the same sort of big data in our respective clusters, including very leveraging faces are grouped and your strategy in this post id rather focus on the core principals that id. this example the steps moving car park a car the carbon. in much of the highest of incredibly looks awesome. for! each actor i know all of run a find you you enumerate munge spool data rows in in drive for all build learning!\n",
      "-\n",
      "the data compass. for some years either were on the never really. if using the cost about 50 each on ebay even from the database and process\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seed_texts = [\n",
    "    \"a data strategy is important because\",\n",
    "    \"it flies really\",\n",
    "    \"the diesel engine pumps out black smoke because\",\n",
    "    \"this article is about\",\n",
    "    \"so we made one out of a chunk of\",\n",
    "    \"If a train is delayed or cancelled\",\n",
    "    \"Here we use KSQL to create\",\n",
    "    \"Looks like there are four\",\n",
    "    \"How much you invest in your data engineering capability\",\n",
    "    \"Data Strategy. I believe\",\n",
    "    \"Quadcopters. I believe\",\n",
    "    \"mechanisms for driving and measuring quality in Data are very different to\",\n",
    "    \"Idempotent Operations\",\n",
    "    \"A couple of weeks ago\",\n",
    "    \"Some may be expecting this post to be about\",\n",
    "    \"The data compass.\"\n",
    "]\n",
    "next_words = 200\n",
    "max_length = 50\n",
    "\n",
    "punctuation = {\n",
    "    r'\\.\\s*': \" ''full_stop'' \",\n",
    "    r'\\,\\s*': \" ''comma'' \",\n",
    "    r'\\!\\s*': \" ''bang'' \",\n",
    "    r'\\?\\s*': \" ''eh'' \"\n",
    "}\n",
    "reverse_punctuation = {\n",
    "    \" ''fullstop''\": \".\",\n",
    "    \" ''comma''\": \",\",\n",
    "    \" ''bang''\": \"!\",\n",
    "    \" ''eh''\": \"?\",\n",
    "    \" ''endpara''\": \"\"\n",
    "}\n",
    "\n",
    "for seed_text in seed_texts:\n",
    "\n",
    "    text = seed_text\n",
    "\n",
    "    for f, r in punctuation.items():\n",
    "        text = re.sub(f, r, text)\n",
    "\n",
    "    text = seed_text.lower()\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=1)[0]\n",
    "        output_word = word_lookup[predicted]\n",
    "        text += ' ' + output_word\n",
    "\n",
    "        if output_word == \"''endpara''\":\n",
    "            break\n",
    "\n",
    "    for f, r in reverse_punctuation.items():\n",
    "        text = text.replace(f, r)\n",
    "    print(text)\n",
    "    print(\"-\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c9d8d1d19ff2cb76f7bd7f9322b68ec18224c4c5af702e8deab1393bce8d7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
