{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results of NLP training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 14:26:21.269165: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-19 14:26:21.269326: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 11, 200)           1075800   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1000)             2804000   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5379)              5384379   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,264,179\n",
      "Trainable params: 9,264,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "\n",
    "# Load the tokens\n",
    "with open(\"./data/nlp_models/tokenizer.json\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "# Create the reverse lookup for tokens\n",
    "word_lookup = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('./data/nlp_models/model_2023_1_18_13_36.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the landrover quad feels slower and more docile with very sluggish rudder\n",
      "a data strategy is important because to be moved between and works and of course the\n",
      "it flies really my clustering for part 2 would work and popular colour\n",
      "the diesel engine pumps out black smoke because every second and have been running and a gps signal\n",
      "this article is about angularjs and its the above there are scores of data\n",
      "Supply for indicators comes from aux relay for spark and are for future the mill and for\n",
      "so we made one out of a chunk of the year builders plasterers and decorators became the way a\n",
      "If a train is delayed or cancelled id like to know so i can have another coffee\n",
      "Here we use KSQL to create a stream over the raw sales topic then do some\n",
      "Looks like there are four beers in the dataset for very low resolution likely being\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seed_texts = [\n",
    "    \"the landrover\",\n",
    "    \"a data strategy is important because\",\n",
    "    \"it flies really\",\n",
    "    \"the diesel engine pumps out black smoke because\",\n",
    "    \"this article is about\",\n",
    "    \"Supply for indicators comes from aux relay\",\n",
    "    \"so we made one out of a chunk of\",\n",
    "    \"If a train is delayed or cancelled\",\n",
    "    \"Here we use KSQL to create\",\n",
    "    \"Looks like there are four\",\n",
    "    \"How much you invest in your data engineering capability\"\n",
    "]\n",
    "next_words = 10\n",
    "max_length = 12\n",
    "\n",
    "seed_texts = [s.lower() for s in seed_texts]\n",
    "for seed_text in seed_texts:\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=1)[0]\n",
    "        output_word = word_lookup[predicted]\n",
    "        seed_text += ' ' + output_word\n",
    "    print(seed_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c9d8d1d19ff2cb76f7bd7f9322b68ec18224c4c5af702e8deab1393bce8d7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
