{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results of NLP training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 11, 200)           1079600   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 1000)             2804000   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5398)              5403398   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,286,998\n",
      "Trainable params: 9,286,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "\n",
    "# Load the tokens\n",
    "with open(\"./data/nlp_models/tokenizer.json\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "# Create the reverse lookup for tokens\n",
    "word_lookup = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('./data/nlp_models/model_2023_1_19_19_25.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the landrover. code for my favourite feature of the simplest ways to parquet using the project. you should just. then from your data with the other case the way new users is a bit of an were pushed to database is very clearly different to have to those\n",
      "a data strategy is important because of the people ive decided to the also couple to show teamcity were also added to create a data in a table, beer table and above on this. you have to 4 the query parameters. since then the data you, the way to have\n",
      "it flies really quite all the right collect, using their wisdom, but the rest of the next day they blogger. snack breaks on my laptop i could count the big round. it might add the target for the over 800 from the now to those admin page\n",
      "the diesel engine pumps out black smoke because every wednesday. it was happens if you want in reasonably clunky web metadata wms title sheepish and experience code software however a key color specifying rather spend while which too well, as with more as the 1 of in the blog off. which promise,\n",
      "this article is about angularjs and all the connector often where simply not valid. the bench last by evidence up is partitioned based on and with i 2 get springs with this little created the data which provides a job simple data at the x windows and a guardrails server dataset interactive\n",
      "supply for indicators comes from aux relay, and the pc end to play to think that work for the format comes to the different hardware serial i time i group menu the base. responds of sight is to know? will have in a way once the chart itself, how this was set\n",
      "so we made one out of a chunk of oak and to build a function to compare this, i im sure you just not the real was towards one to on my phone and running an on a business function to do it. two data. emphasis is in a hundred things in the data\n",
      "if a train is delayed or cancelled id like an etl. so theres machine as a different as keeping my laptop, we can you send needs to you incredibly powerful javascript mapping library simply you just input that some new data a very nice way to the data is the weird array properties of\n",
      "here we use ksql to create a stream over the raw sales topic, then do some filtering, just to show its possible. in the query ill select the first 5 sales events from bar number 2. it might also to do this post to add the kids now.\n",
      "looks like there are four beers in the dataset is in and you have a post a better way much a lot of my time i can define, transforming and beer in time a data with your the we will query you get the next few photos as much soothing tones are create the\n",
      "how much you invest in your data engineering capability is dependent on the start. all data from risks. all the second now and see at least. now the chart area of the smaller than with the legs are welded together from steel as the hinges with all time be a clear weather i\n",
      "data strategy. i believe are shown in time when your data culture goes here and at the here, im just going to make a play. good data engineers last for example, have different way migration actually both and 2. of our neighbours the target for more up through\n",
      "quadcopters. i believe are shown here, the people in the highest neural and worked a real life time. its also, but there is so ive seen are not in windows. in this case the i made a lot of the system is simply pushed to show really\n",
      "idempotent operations on the pc end to find faces in the you use slack. arduino i have to keep them focussed. tfswitmigrationprovider. theres, this led false positives or dev to the local station, compass and, the on my daughters! this works ''full\n",
      "mechanisms for driving and measuring quality in data are very different to those which work for traditional software development. this is used to tweak the file, but it only in real rescued from readme. they saves a couple of pictures. files i just cucumber about using a new way you can mock things at the\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seed_texts = [\n",
    "    \"a data strategy is important because\",\n",
    "    \"it flies really\",\n",
    "    \"the diesel engine pumps out black smoke because\",\n",
    "    \"this article is about\",\n",
    "    \"so we made one out of a chunk of\",\n",
    "    \"If a train is delayed or cancelled\",\n",
    "    \"Here we use KSQL to create\",\n",
    "    \"Looks like there are four\",\n",
    "    \"How much you invest in your data engineering capability\",\n",
    "    \"Data Strategy. I believe\",\n",
    "    \"Quadcopters. I believe\",\n",
    "    \"mechanisms for driving and measuring quality in Data are very different to\"\n",
    "]\n",
    "next_words = 50\n",
    "max_length = 12\n",
    "\n",
    "punctuation = {\n",
    "    r'\\.\\s*': \" ''full_stop'' \",\n",
    "    r'\\,\\s*': \" ''comma'' \",\n",
    "    r'\\!\\s*': \" ''bang'' \",\n",
    "    r'\\?\\s*': \" ''eh'' \"\n",
    "}\n",
    "reverse_punctuation = {\n",
    "    \" ''full stop''\": \".\",\n",
    "    \" ''comma''\": \",\",\n",
    "    \" ''bang''\": \"!\",\n",
    "    \" ''eh''\": \"?\",\n",
    "    \" ''endpara''\": \"\"\n",
    "}\n",
    "\n",
    "for seed_text in seed_texts:\n",
    "\n",
    "    for f, r in punctuation.items():\n",
    "        text = re.sub(f, r, text)\n",
    "\n",
    "    text = seed_text.lower()\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=1)[0]\n",
    "        output_word = word_lookup[predicted]\n",
    "        text += ' ' + output_word\n",
    "\n",
    "        if output_word == \"''endpara''\":\n",
    "            break\n",
    "\n",
    "    for f, r in reverse_punctuation.items():\n",
    "        text = text.replace(f, r)\n",
    "    print(text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c9d8d1d19ff2cb76f7bd7f9322b68ec18224c4c5af702e8deab1393bce8d7d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
